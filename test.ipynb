{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Live Debate ---\n",
      "\n",
      "[MODERATOR]\n",
      "Topic: ronaldo vs messi\n",
      "Decision: ALLOW\n",
      "\n",
      "[PRO - Opening]\n",
      "Ladies and gentlemen, today I stand in favor of the argument that Cristiano Ronaldo is the superior player compared to Lionel Messi. While both athletes are undeniably exceptional, Ronaldo's versatility and physical prowess set him apart. \n",
      "\n",
      "Firstly, Ronaldo has proven himself in multiple leagues—Premier League, La Liga, Serie A—demonstrating his adaptability and skill across different styles of play. In contrast, Messi has spent the majority of his career at Barcelona, raising questions about his performance in varied environments.\n",
      "\n",
      "Secondly, Ronaldo's goal-scoring record is unparalleled. He is the all-time leading scorer in the UEFA Champions League and has consistently outperformed in crucial matches, showcasing his ability to deliver under pressure. \n",
      "\n",
      "Moreover, Ronaldo's work ethic and dedication to fitness have allowed him to maintain peak performance well into his 30s, a testament to his professionalism and commitment to the sport. \n",
      "\n",
      "In conclusion, while both players are legends, Ronaldo's achievements, adaptability, and physical attributes make him the superior choice in the debate of Ronaldo vs. Messi.\n",
      "Key Points: Ronaldo's success in multiple leagues, Unmatched goal-scoring record, Exceptional performance under pressure\n",
      "Citations:\n",
      " • Cristiano Ronaldo vs Lionel Messi: Who is the Greatest of All Time? (https://www.uefa.com/uefachampionsleague/news/0253-0d81c1c1c1c1-1c1c1c1c1c1c1) - A comparison of their achievements and records in football.\n",
      " • The Evolution of Cristiano Ronaldo: A Career in Numbers (https://www.bbc.com/sport/football/54123456) - An analysis of Ronaldo's career statistics and milestones.\n",
      "\n",
      "[CON - Rebuttal]\n",
      "Ladies and gentlemen, while my opponent makes compelling points about Cristiano Ronaldo, I stand firmly in favor of Lionel Messi as the superior player. \n",
      "\n",
      "Firstly, Messi's extraordinary playmaking ability sets him apart. He is not just a prolific goal scorer; he is also a masterful creator, holding the record for the most assists in La Liga history. This dual threat makes him invaluable to his team, as he elevates the performance of those around him.\n",
      "\n",
      "Secondly, Messi's consistency is unmatched. He has maintained an astonishing level of performance throughout his career, winning the Ballon d'Or multiple times and consistently ranking among the top scorers in Europe. His ability to perform in high-pressure situations, including leading Argentina to victory in the Copa America and the World Cup, showcases his resilience and skill.\n",
      "\n",
      "Lastly, Messi's loyalty to Barcelona, where he spent over 20 years, speaks volumes about his character and commitment to a single club, creating a legacy that is deeply intertwined with the team's identity. \n",
      "\n",
      "In conclusion, Messi's unparalleled creativity, consistency, and loyalty make him the true superior in the debate of Ronaldo vs. Messi.\n",
      "Key Points: Messi's playmaking ability enhances team performance., Unmatched consistency in scoring and assists., Loyalty to Barcelona creates a unique legacy.\n",
      "Citations:\n",
      " • Messi vs Ronaldo: Who is the Greatest of All Time? (https://www.example.com/messi-vs-ronaldo) - An analysis of Messi's playmaking and scoring records.\n",
      " • The Impact of Messi on Team Dynamics (https://www.example.com/messi-impact) - Explores how Messi elevates his teammates' performances.\n",
      "\n",
      "[PRO - Rebuttal]\n",
      "Ladies and gentlemen, while my opponent highlights Messi's playmaking and loyalty, I argue that Cristiano Ronaldo's attributes make him the superior player. \n",
      "\n",
      "Firstly, Ronaldo's physical prowess is unparalleled. His combination of speed, strength, and aerial ability allows him to dominate in ways that Messi cannot. Ronaldo's remarkable athleticism has enabled him to excel in various leagues, proving his adaptability by winning titles in England, Spain, and Italy.\n",
      "\n",
      "Secondly, Ronaldo's goal-scoring record is extraordinary. He is the all-time leading scorer in the UEFA Champions League, showcasing his ability to perform at the highest level consistently. His knack for scoring crucial goals in decisive matches, including multiple finals, demonstrates his clutch performance under pressure.\n",
      "\n",
      "Lastly, Ronaldo's work ethic and dedication to self-improvement are legendary. His relentless pursuit of excellence has inspired countless players and fans alike, setting a standard for professionalism in football.\n",
      "\n",
      "In conclusion, Ronaldo's physical dominance, record-breaking goal-scoring, and unmatched work ethic solidify his status as the superior player in the debate of Ronaldo vs. Messi.\n",
      "Key Points: Ronaldo's physical prowess and athleticism, All-time leading scorer in UEFA Champions League, Exceptional performance in multiple leagues and finals\n",
      "Citations:\n",
      " • Cristiano Ronaldo's Goal-Scoring Record (https://www.uefa.com/uefachampionsleague/history/records/) - Cristiano Ronaldo holds the record for the most goals scored in UEFA Champions League history.\n",
      " • Ronaldo's Impact Across Leagues (https://www.bbc.com/sport/football/54123456) - Ronaldo has won league titles in England, Spain, and Italy, showcasing his adaptability.\n",
      "\n",
      "[CON - Closing]\n",
      "While my opponent presents a compelling case for Cristiano Ronaldo, I firmly believe that Lionel Messi is the superior player for several reasons. \n",
      "\n",
      "Firstly, Messi's vision and playmaking ability are unmatched. He not only scores goals but also creates them, leading his teams in assists and demonstrating a unique understanding of the game that elevates his teammates. This holistic approach to football is a testament to his exceptional talent.\n",
      "\n",
      "Secondly, Messi's consistency is remarkable. He has maintained an extraordinary level of performance throughout his career, often leading the league in goals and assists year after year. His ability to perform in high-pressure situations, including crucial matches and finals, speaks volumes about his mental fortitude.\n",
      "\n",
      "Lastly, Messi's loyalty to FC Barcelona, where he spent over 20 years, showcases his commitment to a single club, fostering a deep connection with fans and teammates. This loyalty is a rare quality in modern football, highlighting his character.\n",
      "\n",
      "In conclusion, Messi's unparalleled playmaking, consistent excellence, and loyalty make him the true embodiment of football greatness, surpassing Ronaldo in the debate of who is the better player.\n",
      "Key Points: Messi's playmaking ability enhances team performance., Consistent high-level performance throughout his career., Loyalty to FC Barcelona demonstrates character.\n",
      "Citations:\n",
      " • Messi vs Ronaldo: Who is the Greatest of All Time? (https://www.uefa.com/uefachampionsleague/news/025a-0ea8c1c1c1c1-1c1c1c1c1c1c1) - An analysis of Messi's playmaking and goal contributions.\n",
      " • The Loyalty Factor: Messi's Commitment to Barcelona (https://www.soccer.com/news/messi-loyalty-barcelona) - Exploring Messi's long-term dedication to his club.\n",
      "\n",
      "[JUDGE DECISION]\n",
      "Decision: TIE\n",
      "Rationale: Both debaters presented strong arguments for their respective players, highlighting key attributes such as Ronaldo's physical prowess and adaptability versus Messi's playmaking ability and consistency. The debate ultimately balanced out, as each player has unique strengths that appeal to different f\n",
      "Pro Feedback: The argument for Ronaldo was compelling, particularly regarding his adaptability across leagues and his physical attributes. However, the focus on his goal-scoring could have been complemented with a \n",
      "Con Feedback: The case for Messi was strong, especially in terms of his playmaking and consistency. However, the argument could have benefited from more emphasis on his achievements outside of Barcelona to counter \n",
      "Key Points: Ronaldo's adaptability across multiple leagues demonstrates his versatility., Messi's playmaking ability and consistency elevate his team's performance., Both players have unique strengths that contribute to their greatness.\n",
      "\n",
      "--- Debate Complete ---\n",
      "Final Topic: ronaldo vs messi\n"
     ]
    }
   ],
   "source": [
    "# moderator_app.py\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Optional, Dict, Literal\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # loads OPENAI_API_KEY from .env\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# -----------------------------\n",
    "# 1) STATE (shared memory)\n",
    "# -----------------------------\n",
    "@dataclass\n",
    "class DebateCitation:\n",
    "    title: str\n",
    "    url: str\n",
    "    snippet: Optional[str] = None\n",
    "\n",
    "@dataclass\n",
    "class DebateMessage:\n",
    "    content: str\n",
    "    key_points: List[str] =  field(default_factory=list)\n",
    "    citations: List[DebateCitation] = field(default_factory=list)\n",
    "\n",
    "@dataclass\n",
    "class JudgeMessage:\n",
    "    decision: Literal[\"pro\", \"con\", \"tie\"]\n",
    "    rationale: str\n",
    "    pro_feedback: str\n",
    "    con_feedback: str\n",
    "    key_points: List[str] =  field(default_factory=list)\n",
    "\n",
    "@dataclass\n",
    "class DebateHistory:\n",
    "    role: Literal[\"pro\", \"con\", \"judge\"]\n",
    "    phase: Literal[\"opening\", \"rebuttal\", \"closing\", \"decision\"]\n",
    "    output: DebateMessage\n",
    "\n",
    "@dataclass\n",
    "class DebateState:\n",
    "    topic: str\n",
    "    status: str = \"init\"                       # \"init\" | \"rejected\" | \"ready\"\n",
    "    safety_flags: List[Dict] = field(default_factory=list)  # audit trail\n",
    "    message: Optional[str] = None              # explanation / next-step text\n",
    "    history: List[DebateHistory] = field(default_factory=list)  # past messages\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2) SCHEMA for structured output\n",
    "# -----------------------------\n",
    "Action = Literal[\"allow\", \"rephrase\", \"reject\"]\n",
    "\n",
    "class ModerationResult(BaseModel):\n",
    "    action: Action\n",
    "    categories: List[str] = Field(default_factory=list)     # e.g., [\"illegal_activity\", \"hate\"]\n",
    "    explanation: str                                        # short human-safe rationale\n",
    "    safe_topic: Optional[str] = None                        # required if action == \"rephrase\"\n",
    "    notes: List[str] = Field(default_factory=list)          # optional extra guidance\n",
    "\n",
    "# Use a Pydantic model for structured LLM output, then map to dataclass\n",
    "class DebateCitationModel(BaseModel):\n",
    "    title: str\n",
    "    url: str\n",
    "    snippet: Optional[str] = None\n",
    "\n",
    "class DebateMessageModel(BaseModel):\n",
    "    content: str = Field(..., max_length=2000)  # Limit content length\n",
    "    key_points: List[str] = Field(default_factory=list, max_length=3)  # Limit key points\n",
    "    citations: List[DebateCitationModel] = Field(default_factory=list, max_length=2)  # Limit citations\n",
    "\n",
    "class JudgeMessageModel(BaseModel):\n",
    "    decision: Literal[\"pro\", \"con\", \"tie\"]\n",
    "    rationale: str = Field(..., max_length=300)  # Limit rationale length\n",
    "    pro_feedback: str = Field(..., max_length=200)\n",
    "    con_feedback: str = Field(..., max_length=200)\n",
    "    key_points: List[str] = Field(default_factory=list, max_length=3)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 3) LLM setup with token limits\n",
    "# -----------------------------\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\", \n",
    "    temperature=0,\n",
    "    max_tokens=2000,  # Set a reasonable max_tokens limit\n",
    "    request_timeout=30  # seconds\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 4) NODES\n",
    "# -----------------------------\n",
    "def moderator_node(state: DebateState) -> DebateState:\n",
    "    \"\"\"Classify a topic as allow / rephrase / reject; optionally rephrase it.\"\"\"\n",
    "    # 4a) quick keyword short-circuit (fast, local)\n",
    "    quick_block = [\n",
    "        \"build a bomb\", \"make a bomb\", \"child sexual\", \"sexual content with minors\",\n",
    "        \"self-harm instructions\", \"how to hack\", \"credit card skimming\",\n",
    "        \"assassinate\", \"terrorist\", \"make a gun\", \"kill\"\n",
    "    ]\n",
    "    topic_l = (state.topic or \"\").strip().lower()\n",
    "    if any(k in topic_l for k in quick_block):\n",
    "        res = ModerationResult(\n",
    "            action=\"reject\",\n",
    "            categories=[\"illegal_or_extreme_harm\"],\n",
    "            explanation=\"Disallowed: violent/illegal instruction content.\",\n",
    "            safe_topic=None,\n",
    "            notes=[\"Reframe as an ethics/policy discussion rather than instructions.\"]\n",
    "        )\n",
    "        state.safety_flags.append(res.model_dump())\n",
    "        return state\n",
    "\n",
    "    # 4b) LLM moderation + academic reframe\n",
    "    system = (\n",
    "        \"You are a safety moderator for a debate platform. \"\n",
    "        \"Decide one of: allow | rephrase | reject. \"\n",
    "        \"Disallow topics with step-by-step illegal harm, sexual content with minors, \"\n",
    "        \"self-harm instructions, targeted hate/violence, invasive privacy breaches, malware creation, etc. \"\n",
    "        \"Also don't allow topics that have any relation to religion or politics, the topics should all be \"\n",
    "        \"leaning more towards being lighthearted and less controversial. \"\n",
    "        \"If rephrase: produce a neutral, academic framing (policy/ethics/history) that preserves learning value. \"\n",
    "        \"Also ensure that the rephrase is detailed and provides two clear sides to argue about. \"\n",
    "        \"Keep your response concise. Return ONLY structured JSON matching the provided schema.\"\n",
    "    )\n",
    "    user = f'Topic: \"{state.topic}\"'\n",
    "\n",
    "    mod_llm = llm.with_structured_output(schema=ModerationResult)\n",
    "    result: ModerationResult = mod_llm.invoke(f\"{system}\\n\\n{user}\")\n",
    "\n",
    "    # audit trail\n",
    "    state.safety_flags.append(result.model_dump())\n",
    "\n",
    "    # apply rephrase if given\n",
    "    if result.action == \"rephrase\" and result.safe_topic:\n",
    "        state.topic = result.safe_topic\n",
    "\n",
    "    return state\n",
    "\n",
    "def moderator_router(state: DebateState) -> str:\n",
    "    \"\"\"Decide which node to run after moderator.\"\"\"\n",
    "    last = state.safety_flags[-1] if state.safety_flags else {}\n",
    "    action = last.get(\"action\")\n",
    "    if action == \"reject\":\n",
    "        return \"reject_exit\"\n",
    "    return \"proceed\"  # allow OR rephrase both continue\n",
    "\n",
    "def reject_exit(state: DebateState) -> DebateState:\n",
    "    state.status = \"rejected\"\n",
    "    last = state.safety_flags[-1] if state.safety_flags else {}\n",
    "    state.message = f\"❌ Rejected. Reason: {last.get('explanation','')}\"\n",
    "    return state\n",
    "\n",
    "def proceed_node(state: DebateState) -> DebateState:\n",
    "    state.status = \"ready\"\n",
    "    last = state.safety_flags[-1] if state.safety_flags else {}\n",
    "    if last.get(\"action\") == \"rephrase\":\n",
    "        state.message = f\"✅ Rephrased to safe topic: {state.topic}. Ready to start the debate flow.\"\n",
    "    else:\n",
    "        state.message = f\"✅ Allowed topic: {state.topic}. Ready to start the debate flow.\"\n",
    "    return state\n",
    "\n",
    "\n",
    "# ---------- PRO / CON NODES ----------\n",
    "def pro_node(state: DebateState) -> DebateState:\n",
    "    \"\"\"Generate Pro opening or rebuttal, then store into history.\"\"\"\n",
    "    system = (\n",
    "        \"You are the 'Pro' debater in a formal debate. \"\n",
    "        \"Support the topic with clear reasoning and evidence. \"\n",
    "        \"Be concise and persuasive. Keep your response between 150-200 words. \"\n",
    "        # \"Focus on 2-3 key points maximum. Provide 1-2 citations if relevant.\"\n",
    "    )\n",
    "    mod_llm = llm.with_structured_output(schema=DebateMessageModel)\n",
    "\n",
    "    if not state.history:\n",
    "        # Pro Opening\n",
    "        prompt = f\"Topic: {state.topic}\\n\\nProvide a concise opening argument supporting this position.\"\n",
    "        result: DebateMessageModel = mod_llm.invoke(f\"{system}\\n\\n{prompt}\")\n",
    "        msg = DebateMessage(\n",
    "            content=result.content,\n",
    "            key_points=result.key_points,\n",
    "            citations=[DebateCitation(**c.model_dump()) for c in result.citations]\n",
    "        )\n",
    "        state.history.append(DebateHistory(role=\"pro\", phase=\"opening\", output=msg))\n",
    "    else:\n",
    "        # Pro Rebuttal (respond to last turn)\n",
    "        prior_text = state.history[-1].output.content\n",
    "        prompt = (\n",
    "            f\"Topic: {state.topic}\\n\\n\"\n",
    "            f\"Previous opposing argument: {prior_text}\\n\\n\"\n",
    "            f\"Provide a concise rebuttal supporting your position.\"\n",
    "        )\n",
    "        result: DebateMessageModel = mod_llm.invoke(f\"{system}\\n\\n{prompt}\")\n",
    "        msg = DebateMessage(\n",
    "            content=result.content,\n",
    "            key_points=result.key_points,\n",
    "            citations=[DebateCitation(**c.model_dump()) for c in result.citations]\n",
    "        )\n",
    "        state.history.append(DebateHistory(role=\"pro\", phase=\"rebuttal\", output=msg))\n",
    "    \n",
    "    return state\n",
    "\n",
    "def con_node(state: DebateState) -> DebateState:\n",
    "    \"\"\"Generate Con rebuttal or closing, then store into history.\"\"\"\n",
    "    system = (\n",
    "        \"You are the 'Con' debater in a formal debate. \"\n",
    "        \"Oppose the topic with clear reasoning and evidence. \"\n",
    "        \"Be concise and persuasive. Keep your response between 150-200 words. \"\n",
    "        # \"Focus on 2-3 key points maximum. Provide 1-2 citations if relevant. \"\n",
    "    )\n",
    "    mod_llm = llm.with_structured_output(schema=DebateMessageModel)\n",
    "\n",
    "    # Safety: if somehow called first, do a rebuttal vs nothing\n",
    "    prior_text = state.history[-1].output.content if state.history else \"\"\n",
    "\n",
    "    # If the last phase was Pro opening -> Con rebuttal, else Con closing\n",
    "    if state.history and state.history[-1].phase == \"opening\":\n",
    "        prompt = (\n",
    "            f\"Topic: {state.topic}\\n\\n\"\n",
    "            f\"Previous Pro argument: {prior_text}\\n\\n\"\n",
    "            f\"Provide a concise rebuttal opposing this position.\"\n",
    "        )\n",
    "        phase = \"rebuttal\"\n",
    "    else:\n",
    "        prompt = (\n",
    "            f\"Topic: {state.topic}\\n\\n\"\n",
    "            f\"Previous argument: {prior_text}\\n\\n\"\n",
    "            f\"Provide a concise closing argument opposing this position.\"\n",
    "        )\n",
    "        phase = \"closing\"\n",
    "\n",
    "    result: DebateMessageModel = mod_llm.invoke(f\"{system}\\n\\n{prompt}\")\n",
    "    msg = DebateMessage(\n",
    "        content=result.content,\n",
    "        key_points=result.key_points,\n",
    "        citations=[DebateCitation(**c.model_dump()) for c in result.citations]\n",
    "    )\n",
    "    state.history.append(DebateHistory(role=\"con\", phase=phase, output=msg))\n",
    "    return state\n",
    "\n",
    "def judge_node(state: DebateState) -> DebateState:\n",
    "    \"\"\"Generate judge evaluation with strict length limits.\"\"\"\n",
    "    system = (\n",
    "        \"You are the Judge in a formal debate. \"\n",
    "        \"Evaluate the arguments and provide a structured judgment. \"\n",
    "        \"Be concise: rationale max 100 words, feedback max 75 words each. \"\n",
    "        \"Focus on the strongest 2-3 key points that determined your decision.\"\n",
    "    )\n",
    "    mod_llm = llm.with_structured_output(schema=JudgeMessageModel)\n",
    "    \n",
    "    # Summarize debate history concisely to avoid token overflow\n",
    "    debate_summary = []\n",
    "    for h in state.history:\n",
    "        debate_summary.append(f\"{h.role.upper()} ({h.phase}): {h.output.content}\")\n",
    "    \n",
    "    prompt = (\n",
    "        f\"Topic: {state.topic}\\n\\n\"\n",
    "        f\"Debate Summary:\\n\" + \"\\n\\n\".join(debate_summary) + \"\\n\\n\"\n",
    "        f\"Provide your judgment.\"\n",
    "    )\n",
    "    \n",
    "    result: JudgeMessageModel = mod_llm.invoke(f\"{system}\\n\\n{prompt}\")\n",
    "    \n",
    "    msg = JudgeMessage(\n",
    "        decision=result.decision,\n",
    "        rationale=result.rationale,\n",
    "        pro_feedback=result.pro_feedback,\n",
    "        con_feedback=result.con_feedback,\n",
    "        key_points=result.key_points\n",
    "    )\n",
    "    state.history.append(DebateHistory(role=\"judge\", phase=\"decision\", output=msg))\n",
    "    return state\n",
    "\n",
    "\n",
    "# ---------- FLOW ROUTER ----------\n",
    "def debate_flow_router(state: DebateState) -> str:\n",
    "    \"\"\"\n",
    "    Turn order:\n",
    "      - (no history) -> pro (opening)\n",
    "      - after pro opening -> con (rebuttal)\n",
    "      - after con rebuttal -> pro (rebuttal)\n",
    "      - after pro rebuttal -> con (closing)\n",
    "      - after con closing -> judge\n",
    "      - after judge -> END\n",
    "    \"\"\"\n",
    "    if not state.history:\n",
    "        return \"pro\"\n",
    "\n",
    "    last = state.history[-1]\n",
    "    if last.role == \"pro\" and last.phase in (\"opening\", \"rebuttal\"):\n",
    "        return \"con\"\n",
    "\n",
    "    if last.role == \"con\":\n",
    "        if last.phase == \"rebuttal\":\n",
    "            return \"pro\"\n",
    "        if last.phase == \"closing\":\n",
    "            return \"judge\"\n",
    "    \n",
    "    if last.role == \"judge\":\n",
    "        return \"__end__\"\n",
    "\n",
    "    # Fallback\n",
    "    return \"__end__\"\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 5) GRAPH WIRING\n",
    "# -----------------------------\n",
    "graph = StateGraph(DebateState)\n",
    "\n",
    "# Existing nodes\n",
    "graph.add_node(\"moderator\", moderator_node)\n",
    "graph.add_node(\"reject_exit\", reject_exit)\n",
    "graph.add_node(\"proceed\", proceed_node)\n",
    "\n",
    "# New debate nodes\n",
    "graph.add_node(\"pro\", pro_node)\n",
    "graph.add_node(\"con\", con_node)\n",
    "graph.add_node(\"judge\", judge_node)\n",
    "\n",
    "graph.set_entry_point(\"moderator\")\n",
    "\n",
    "# Moderator decides whether to proceed or reject\n",
    "graph.add_conditional_edges(\n",
    "    \"moderator\",\n",
    "    moderator_router,\n",
    "    {\"reject_exit\": \"reject_exit\", \"proceed\": \"proceed\"}\n",
    ")\n",
    "\n",
    "graph.add_edge(\"reject_exit\", END)\n",
    "\n",
    "# Enter debate flow after proceed\n",
    "graph.add_conditional_edges(\n",
    "    \"proceed\",\n",
    "    debate_flow_router,\n",
    "    {\"pro\": \"pro\", \"con\": \"con\", \"__end__\": END}\n",
    ")\n",
    "\n",
    "# Keep routing between pro/con until closing -> END\n",
    "graph.add_conditional_edges(\n",
    "    \"pro\",\n",
    "    debate_flow_router,\n",
    "    {\"pro\": \"pro\", \"con\": \"con\", \"__end__\": END}\n",
    ")\n",
    "graph.add_conditional_edges(\n",
    "    \"con\",\n",
    "    debate_flow_router,\n",
    "    {\"pro\": \"pro\", \"con\": \"con\", \"judge\": \"judge\", \"__end__\": END}\n",
    ")\n",
    "graph.add_conditional_edges(\n",
    "    \"judge\",\n",
    "    debate_flow_router,\n",
    "    {\"__end__\": END}\n",
    ")\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "# -----------------------------\n",
    "# 6) CLI entrypoint\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        topic = input(\"Enter a debate topic: \")\n",
    "    except KeyboardInterrupt:\n",
    "        raise SystemExit\n",
    "\n",
    "    initial = DebateState(topic=topic)\n",
    "\n",
    "    print(\"\\n--- Live Debate ---\")\n",
    "    final_state = None\n",
    "\n",
    "    for event in app.stream(initial):  \n",
    "        for node_name, payload in event.items():\n",
    "            # In default mode, payload is a dict with metadata (value, logs, etc.)\n",
    "            state = payload.get(\"value\", payload)\n",
    "\n",
    "            if node_name == \"moderator\":\n",
    "                flags = state.get(\"safety_flags\", [])\n",
    "                last = flags[-1] if flags else {}\n",
    "                action = last.get(\"action\")\n",
    "                print(\"\\n[MODERATOR]\")\n",
    "                print(\"Topic:\", state.get(\"topic\"))\n",
    "                if action == \"reject\":\n",
    "                    print(\"Decision: REJECT\")\n",
    "                    print(\"Reason:\", last.get(\"explanation\", \"\"))\n",
    "                elif action == \"rephrase\":\n",
    "                    print(\"Decision: REPHRASE\")\n",
    "                    print(\"Safe Topic:\", state.get(\"topic\"))\n",
    "                    print(\"Why:\", last.get(\"explanation\", \"\"))\n",
    "                else:\n",
    "                    print(\"Decision: ALLOW\")\n",
    "\n",
    "            elif node_name in (\"pro\", \"con\"):\n",
    "                hlist = state.get(\"history\", [])\n",
    "                if not hlist:\n",
    "                    continue\n",
    "                h = hlist[-1]  # DebateHistory dataclass\n",
    "                role = h.role.upper()\n",
    "                phase = h.phase.capitalize()\n",
    "                out = h.output  # DebateMessage dataclass\n",
    "                print(f\"\\n[{role} - {phase}]\")\n",
    "                print(out.content)\n",
    "                if out.key_points:\n",
    "                    print(\"Key Points:\", \", \".join(out.key_points))\n",
    "                if out.citations:\n",
    "                    print(\"Citations:\")\n",
    "                    for c in out.citations:\n",
    "                        snip = f\" - {c.snippet}\" if c.snippet else \"\"\n",
    "                        print(f\" • {c.title} ({c.url}){snip}\")\n",
    "\n",
    "            elif node_name == \"judge\":\n",
    "                hlist = state.get(\"history\", [])\n",
    "                if not hlist:\n",
    "                    continue\n",
    "                h = hlist[-1]\n",
    "                out = h.output  # JudgeMessage dataclass\n",
    "                print(\"\\n[JUDGE DECISION]\")\n",
    "                print(\"Decision:\", getattr(out, \"decision\", \"\").upper())\n",
    "                print(\"Rationale:\", getattr(out, \"rationale\", \"\"))\n",
    "                pf = getattr(out, \"pro_feedback\", \"\")\n",
    "                cf = getattr(out, \"con_feedback\", \"\")\n",
    "                if pf:\n",
    "                    print(\"Pro Feedback:\", pf)\n",
    "                if cf:\n",
    "                    print(\"Con Feedback:\", cf)\n",
    "                kps = getattr(out, \"key_points\", []) or []\n",
    "                if kps:\n",
    "                    print(\"Key Points:\", \", \".join(kps))\n",
    "\n",
    "            final_state = state  # keep latest\n",
    "\n",
    "    if final_state:\n",
    "        print(\"\\n--- Debate Complete ---\")\n",
    "        print(\"Final Topic:\", final_state.get(\"topic\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
